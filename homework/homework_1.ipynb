{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bff85910",
   "metadata": {},
   "source": [
    "# HWRS640 - Assignment 1: Computer architecture and parallel computing\n",
    "\n",
    "Hossein Yousefi Sohi - Feb 05, 2026\n",
    "\n",
    "## Problem 1: Supercomputer architecture\n",
    "1.\t Name + location\n",
    "Frontier was ranked #1 on the TOP500 November 2022 list. It is installed at Oak Ridge National Laboratory in Oak Ridge, Tennessee, United States.\n",
    "\n",
    "2.\t Architecture (CPU, cores, memory, interconnect)\n",
    "Frontier is an HPE Cray EX235a system built by Hewlett Packard Enterprise and designed as a hybrid CPU–GPU machine. On the TOP500 entry, its compute nodes are based on AMD “Optimized 3rd Gen EPYC” 64-core 2.0 GHz CPUs paired with AMD Instinct MI250X accelerators, and the system uses the HPE Slingshot-11 interconnect. In the November 2022 configuration, TOP500 reports 8,730,112 total cores (TOP500’s accounting of “cores” reflects the benchmark reporting model for the full system).\n",
    "At the node level, Frontier’s user documentation describes a clear, repeatable building block: 1× 64-core EPYC CPU with 512 GB DDR4, plus 4× MI250X GPUs. Each MI250X contains two GPU dies; the documentation notes you can think of these as 8 GPU devices per node, each with 64 GB of high-bandwidth memory (HBM2E)—i.e., 512 GB HBM2E per node alongside the 512 GB CPU memory.\n",
    "\n",
    "3.\tPeak performance (FLOPS)\n",
    "TOP500 reports two performance numbers for Frontier in November 2022:\n",
    "•\tTheoretical peak (Rpeak): 1,685.65 PFLOP/s = 1.68565 × 10¹⁸ FLOP/s (≈ 1.69 EFLOP/s)\n",
    "•\tLINPACK achieved (Rmax): 1,102.00 PFLOP/s = 1.10200 × 10¹⁸ FLOP/s (≈ 1.10 EFLOP/s)\n",
    "\n",
    "4.\tCapability\n",
    "Frontier’s impact goes beyond raw FLOPS. By combining CPU–GPU parallelism with very high memory bandwidth and a fast interconnect, it enables either larger simulations or faster time-to-solution. This is especially valuable for kilometer-scale climate/Earth-system ensembles, multi-physics energy and nuclear modeling with uncertainty quantification, and data-intensive workflows where in-situ analysis and scientific machine learning are tightly coupled to simulation output.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
